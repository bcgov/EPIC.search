name: epic-search
services:  
  epic-search-db:
    image: pgvector/pgvector:pg17
    volumes:
      - db-data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=postgres
    ports:
      - 5432:5432/tcp
    restart: unless-stopped
    networks: 
      - common-network
  epic-search-model:
    image: epic-search/model:latest
    build:
      context: /search-model/.
      dockerfile: Dockerfile
      args:
        - MODEL_NAME=qwen2.5
        - MODEL_VERSION=0.5b
    volumes:
      - llm-data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=-1
      - MODEL_NAME=qwen2.5
      - MODEL_VERSION=0.5b
    ports:
      - 11434:11434/tcp
    restart: unless-stopped
    networks: 
      - common-network  
  epic-search-vector-api:
    image: epic-search/vector-api:latest
    build:
      context: /search-vector-api/.
      dockerfile: Dockerfile
    volumes:
      - torch-cache:/root/.cache/torch/sentence_transformers
      - transformer-cache:/root/.cache/huggingface/transformers    
    environment:
      - FLASK_ENV=development
      - VECTOR_TABLE=document_tags
      - EMBEDDING_DIMENSIONS=768
      - KEYWORD_FETCH_COUNT=100
      - SEMANTIC_FETCH_COUNT=100
      - TOP_RECORD_COUNT=10
      - RERANKER_BATCH_SIZE=8
      - VECTOR_DB_URL=postgresql://postgres:password@epic-search-db:5432/postgres
      - CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-2-v2
      - EMBEDDING_MODEL_NAME=all-mpnet-base-v2
      - KEYWORD_MODEL_NAME=all-mpnet-base-v2
      # Set to true to preload models at container startup
      - PRELOAD_MODELS=true
      - MIN_RELEVANCE_SCORE=-8.0
    ports:
      - 3300:8080/tcp
    depends_on:
      epic-search-db:
        condition: service_started
      epic-search-model:
        condition: service_started      
    restart: unless-stopped
    networks: 
      - common-network
  epic-search-api:
    image: epic-search/api:latest
    build:
      context: /search-api/.
      dockerfile: Dockerfile
    environment:      
      - CORS_ORIGIN=*
      - S3_BUCKET_NAME=<BUCKET_NAME>
      - S3_ACCESS_KEY_ID=<S3_ACCESS_KEY_ID>
      - S3_SECRET_ACCESS_KEY=<S3_SECRET_ACCESS_KEY>
      - S3_REGION=us-east-1
      - S3_ENDPOINT_URI=https://nrs.objectstore.gov.bc.ca
      - VECTOR_SEARCH_API_URL=http://epic-search-vector-api:8080/api/vector-search
      # LLM Provider Configuration
      - LLM_PROVIDER=ollama
      - LLM_TEMPERATURE=0.3
      - LLM_MAX_TOKENS=1000
      - LLM_MAX_CONTEXT_LENGTH=8192
      # Ollama Configuration (required if LLM_PROVIDER=ollama)
      - LLM_MODEL=qwen2.5:0.5b
      - LLM_HOST=http://epic-search-model:11434     
    ports:
      - 3200:8080/tcp
    depends_on:
      epic-search-db:
        condition: service_started
      epic-search-model:
        condition: service_started
    restart: unless-stopped
    networks: 
      - common-network
volumes:
  db-data:    
  llm-data:
  transformer-cache:
  torch-cache:

networks:
  common-network:
    driver: bridge